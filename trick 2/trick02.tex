\documentclass[11pt,table]{beamer}
\mode<presentation>
\usepackage{etex}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage[english]{babel}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{mathrsfs}
\usepackage{multicol}
\usepackage{bm}
\usepackage{subcaption}
\usepackage{wrapfig}
\usepackage{dcolumn}
\usepackage{threeparttable}
\usepackage{booktabs}
\usepackage{bbm}
\usepackage{amsmath,dsfont,listings}
\usepackage{amssymb}
\usepackage{rotating}
\usepackage{multirow}
\usepackage[authoryear]{natbib}
\usepackage{circledsteps}
\usepackage{tikz}
\usetikzlibrary{arrows,decorations.pathmorphing,backgrounds,fit,positioning,shapes.symbols,chains}
\setbeamertemplate{section in toc}[sections numbered]
\setbeamertemplate{caption}[numbered]

\bibliographystyle{Econometrica}

\setbeamersize{text margin right=3.5mm, text margin left=7.5mm}  % text margin
\setbeamersize{sidebar width left=0cm, sidebar width right=0mm}
\setbeamertemplate{sidebar right}{}
\setbeamertemplate{sidebar left}{}

\definecolor{text-grey}{rgb}{0.45, 0.45, 0.45} % grey text on white background
\definecolor{bg-grey}{rgb}{0.66, 0.65, 0.60} % grey background (for white text)
\definecolor{fu-blue}{RGB}{0, 51, 102} % blue text
\definecolor{fu-green}{RGB}{153, 204, 0} % green text
\definecolor{fu-red}{RGB}{204, 0, 0} % red text (used by \alert)

\setbeamertemplate{frametitle}{%
    \vskip-30pt \color{text-grey}\large%
    \begin{minipage}[b][23pt]{80.5mm}%
    \flushleft\insertframetitle%
    \end{minipage}%
}

\setbeamertemplate{navigation symbols}{} 

%%% begin title page
\setbeamertemplate{title page}{
\vskip2pt\hfill
\vskip6pt\hskip3pt

% set the title and the author
\vskip14pt
\parbox[top][1.35cm][c]{11cm}{\LARGE\color{text-grey}\inserttitle \\[1ex] \small \insertsubtitle \\[3ex]}
\vskip11pt
\parbox[top][1.35cm][c]{11cm}{\small \insertauthor \; \insertinstitute \\[2ex] \insertdate}
}
%%% end title page

%%% colors
\usecolortheme{lily}
\setbeamercolor*{normal text}{fg=black,bg=white}
\setbeamercolor*{alerted text}{fg=fu-red}
\setbeamercolor*{example text}{fg=fu-green}
\setbeamercolor*{structure}{fg=fu-blue}

\setbeamercolor*{block title}{fg=white,bg=black!50}
\setbeamercolor*{block title alerted}{fg=white,bg=black!50}
\setbeamercolor*{block title example}{fg=white,bg=black!50}

\setbeamercolor*{block body}{bg=black!10}
\setbeamercolor*{block body alerted}{bg=black!10}
\setbeamercolor*{block body example}{bg=black!10}

\setbeamercolor{bibliography entry author}{fg=fu-blue}
\setbeamercolor{bibliography entry journal}{fg=text-grey}
\setbeamercolor{item}{fg=fu-blue}
\setbeamercolor{navigation symbols}{fg=text-grey,bg=bg-grey}
%%% end colors

%%% headline
\setbeamertemplate{headline}{
\vskip30pt
}
%%% end headline

%%% footline
\newcommand{\footlinetext}{
%\insertshortinstitute, \insertshorttitle, \insertshortdate
}
\setbeamertemplate{footline}{
\vskip2pt
\hfill \raisebox{-1pt}{\usebeamertemplate***{navigation symbols}}
\hfill \insertframenumber\hspace{10pt}
\vskip4pt
}
%%% end footline

%%% settings for listings package
\lstset{extendedchars=true, showstringspaces=false, basicstyle=\footnotesize\sffamily, tabsize=2, breaklines=true, breakindent=10pt, frame=l, columns=fullflexible}
\lstset{language=Java} % this sets the syntax highlighting
\lstset{mathescape=true} % this switches on $...$ substitution in code
% enables UTF-8 in source code:
\lstset{literate={ä}{{\"a}}1 {ö}{{\"o}}1 {ü}{{\"u}}1 {Ä}{{\"A}}1 {Ö}{{\"O}}1 {Ü}{{\"U}}1 {ß}{\ss}1}
%%% end listings

\usepackage{concmath}
\usepackage{xcolor}
\definecolor{red1}{RGB}{206, 17, 38}
\definecolor{blue1}{RGB}{16, 118, 208}
\definecolor{gray1}{RGB}{117, 115, 115}
\usepackage{hyperref}
\hypersetup{
    bookmarks=false,
    unicode=false,
    pdftoolbar=false,
    pdffitwindow=true,
    pdftitle={Econometricks: Short guides to econometrics},
    pdfauthor={Davud Rostam-Afschar},
    pdfsubject={econometrics},
    pdfcreator={Davud Rostam-Afschar},
    pdfproducer={Davud Rostam-Afschar},
    pdfkeywords={econometrics},
    pdfnewwindow=true,
}

\newtheorem{proposition}{Proposition}
\newtheorem{assumption}{Definition}


\title[] 
{Econome\textcolor{red1}{tricks}: Short guides to econometrics\\[1ex]\normalsize 
}

\author[D. Rostam-Afschar]{Trick 02: Specific Distributions\\[2ex]}

\institute[]{\textcolor{gray1}{Davud Rostam-Afschar (Uni Mannheim)}}
            
\date[] 
{}

\subject{Econometrics}
\renewcommand{\footlinetext}{\insertshortinstitute, \insertshorttitle, \insertshortdate}

\def\sym#1{\ifmmode^{#1}\else\(^{#1}\)\fi}

\begin{document}

\begin{frame}[plain]
  \titlepage
\end{frame}

% --------------------------------------------------- Slide --
\begin{frame}
	\frametitle{Content}
	\tableofcontents[]
\end{frame}



\begin{frame}{Specific Distributions}
\begin{figure}[H]
\begin{center}
{\includegraphics[width=0.8\textwidth]{figures/distributions}}\label{f1}
\end{center}
\end{figure}
\tiny Thanks to Ping Yu
\end{frame}


\begin{frame}{Discrete distributions}
The $\textbf{Bernoulli distribution}$ for a single binomial outcome (trial) is
\begin{eqnarray*}
  Prob(x = 1) &=& p, \\
  Prob(x = 0) &=& 1-p,
\end{eqnarray*}
where $0 \leq p \leq 1$ is the probability of success.

\begin{itemize}
	\item  $E[x]=p$ and 
	\item $V[x]=E[x^2]-E[x]^2=p-p^2=p(1-p)$.
\end{itemize}
 

\end{frame}

\begin{frame}{Discrete distributions}
 The distribution for $x$ successes in $n$ trials is the $\textbf{binomial distribution}$,
\begin{equation*}
    Prob(X = x) =\frac{n!}{(n-x)!x!}p^{x}(1-p)^{n-x}~~~x =0, 1,\ldots, n.
\end{equation*}
The mean and variance of $x$ are
\begin{itemize}
	\item  $E[x]=np$ and 
	\item $V[x]=np(1 - p)$.
\end{itemize}

Example of a binomial $[n=15,p=0.5]$ distribution:

\begin{figure}[H]
\begin{center}
%\scalebox{.36}
{\includegraphics[width=0.45\textwidth]{figures/binomial_pdf}
\includegraphics[width=0.45\textwidth]{figures/binomial_cdf}}\label{f2}
\end{center}
\end{figure}
\end{frame}


\begin{frame}{Discrete distributions}

The limiting form of the binomial distribution, $n\rightarrow\infty$, is the $\textbf{Poisson distribution}$,
\begin{equation*}
    Prob(X = x) =\frac{e^{\lambda}\lambda^{x}}{x!}.
\end{equation*}
The mean and variance of $x$ are
\begin{itemize}
	\item  $E[x]=\lambda$ and 
	\item $V[x]=\lambda$.
\end{itemize}

Example of a Poisson $[3]$ distribution:

\begin{figure}[H]
\begin{center}
%\scalebox{.36}
{\includegraphics[width=0.45\textwidth]{figures/poisson_pdf}}\label{f4}
\end{center}
\end{figure}
\end{frame}




\section{The normal distribution}

\begin{frame}{The normal distribution}

Random variable $x \sim N[\mu, \sigma^{2}]$ is distributed according to the $\textbf{normal distribution}$ with mean $\mu$ and standard deviation $\sigma$ obtained as
\begin{equation}
    f(x|\mu, \sigma)=\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{1}{2}(\frac{x-\mu}{\sigma})^2}.
\end{equation}

The density is denoted $\phi(x)$ and the cumulative distribution function is denoted $\Phi(x)$ for the standard normal. Example of a standard normal, ($x\sim N[0, 1]$), and a normal with mean $0.5$ and standard deviation $1.3$:

\begin{figure}[H]
\begin{center}
%\scalebox{.36}
{\includegraphics[width=0.45\textwidth]{figures/normals_pdf}}\label{f4}
\end{center}
\end{figure}
\end{frame}


\section{Method of transformations}
\begin{frame}{Transformation of random variables}
\renewcommand{\baselinestretch}{1.45}

Continuous variable $x$ may be transformed to a discrete variable $y$. Calculate the mean of variable $x$ in the respective interval:
\begin{eqnarray*}
  Prob(Y = \mu_{1}) &=& P(-\infty < X \leq a), \\
  Prob(Y = \mu_{2})  &=& P(a < X \leq b), \\
  Prob(Y = \mu_{3})  &=& P(b < X \leq \infty).\\
\end{eqnarray*}

\end{frame}


\begin{frame}{Method of transformations}
\renewcommand{\baselinestretch}{1.}
\scriptsize
If $x$ is a continuous random variable with pdf $f_{x}(x)$ and if $y = g(x)$ is a continuous monotonic function of $x$, then the density of $y$ is obtained by
\begin{equation*}
    Prob(y \leq b) =\int_{-\infty}^{b}f_{x}(g^{-1}(y))|g^{-1\prime}(y)|dy.
\end{equation*}
With $f_{y}(y)=f_{x}(g^{-1}(y))|g^{-1\prime}](y)|dy$, this equation can be written as
$$Prob(y \leq b) =\int_{-\infty}^{b}f_{y}(y)dy.$$
\begin{example}\renewcommand{\baselinestretch}{0.9}
\scriptsize
If $x \sim N[\mu, \sigma^{2}],$ then the distribution of $y=g(x)=\frac{x-\mu}{\sigma}$ is found as follows:
$$g^{-1}(y)= x=\sigma y+\mu$$
$$g^{-1\prime}(y)= \frac{dx}{dy}=\sigma$$
Therefore with $f_x(x)=\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{1}{2}[(g^{-1}(y)-\mu)^2/\sigma^{2}]}|g^{-1\prime}(y)|$
\begin{equation*}
    f_{y}(y)=\frac{1}{\sqrt{2\pi}\sigma}e^{-[(\sigma y+\mu)-\mu]^{2}/2\sigma^{2}}|\sigma|=\frac{1}{\sqrt{2\pi}}e^{-y^{2}/2}.
\end{equation*}
\end{example}

\end{frame}

\begin{frame}{Properties of the normal distribution}
\renewcommand{\baselinestretch}{1.45}

\begin{itemize}
	\item Preservation under linear transformation:\\
 If $x \sim N[\mu, \sigma^{2}],$ then $(a + bx) \sim N[a + b\mu, b^{2}\sigma^{2}].$
\item Convenient transformation $a = -\mu/\sigma$ and $b = 1/\sigma$:\\
 The resulting variable $z=\frac{(x - \mu)}{\sigma}$ has the standard normal distribution with density $$\phi(z)=\frac{1}{\sqrt{2\pi}}e^{-\frac{z^{2}}{2}}.$$
\item If $x \sim N[\mu,\sigma^{2}]$, then $f(x)=\frac{1}{\sigma}\phi[\frac{x-\mu}{\sigma}]$
\item $Prob(a \leq x \leq b) = Prob\left(\frac{a-\mu}{\sigma}\leq\frac{x-\mu}{\sigma}\leq\frac{b-\mu}{\sigma}\right)$
\item $\phi(-z) = 1 - \phi(z)$ and $\Phi(-x)=1-\Phi(x)$ because of symmetry
\end{itemize}
\end{frame}


\begin{frame}{Method of transformations}
\renewcommand{\baselinestretch}{1.}
If $z \sim N[0, 1]$, then $z^{2} \sim \chi^2[1]$ with pdf $\frac{1}{\sqrt{2\pi y}}e^{-y/2}$.
\begin{example}\renewcommand{\baselinestretch}{0.9}
\scriptsize
$$f_x(x)=\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}$$
$$y=g(x)=x^2$$
$$g^{-1}(y)= x=\pm \sqrt{y} \text{ there are two solutions to } g_1,g_2.$$
$$g^{-1\prime}(y)= \frac{dx}{dy}=\pm 1/2y^{-1/2}$$
$$f_{y}(y)=f_x(g_1^{-1}(y))|g_1^{-1\prime}(y)|+f_x(g_2^{-1}(y))|g_2^{-1\prime}(y)|$$
$$f_{y}(y)=f_x(\sqrt{y})|1/2y^{-1/2}|+f_x(-\sqrt{y})|-1/2y^{-1/2}|$$
$$f_{y}(y)=\frac{1}{2\sqrt{2\pi y}}e^{-\frac{y}{2}}+\frac{1}{2\sqrt{2\pi y}}e^{-\frac{y}{2}}=\frac{1}{\sqrt{2\pi y}}e^{-\frac{y}{2}}$$
\end{example}

\end{frame}

\begin{frame}{Distributions derived from the normal}
\footnotesize
\begin{itemize}
  \item If $z \sim N[0, 1]$, then $z^{2} \sim \chi^2[1]$ with $E[z^2]=1$ and $V[z^2]=2$.
  \item If $x_{1},..., x_{n}$ are $n$ independent $\chi^2[1]$ variables, then $$\sum_{i=1}^{n}x_{i}\sim \chi^2[n].$$
  \item If $z_{i},i = 1,..., n,$ are independent $N[0, 1]$ variables, then $$\sum_{i=1}^{n}z_{i}^{2}\sim \chi^{2}[n].$$
  \item If $z_{i},i = 1,..., n$, are independent $N[0, \sigma^2]$ variables, then $$\sum_{i=1}^{n}\bigg(\frac{z_{i}}{\sigma}\bigg)^{2}\sim \chi^{2}[n].$$
  \item If $x_{1}$ and $x_{2}$ are independent $\chi^2$ variables with $n_{1}$ and $n_{2}$ degrees of freedom, then $$x_{1} + x_{2} \sim \chi^{2}[n_{1} + n_{2}].$$
\end{itemize}
\end{frame}


\section{The $\chi^2$ distribution}
\begin{frame}{The $\chi^2$ distribution}

Random variable $x \sim \chi^2[n]$ is distributed according to the $\textbf{ chi-squared distribution}$ with $n$ degrees of freedom
\begin{equation}
    f(x|n)=\dfrac{x^{n/2 -1} e^{-x/2}}{2^{n/2} \Gamma\left(\frac n 2 \right)},
\end{equation}

where $\Gamma$ is the Gamma-distribution (more below).
\begin{itemize}
	\item $E[x]=n$
  \item $V[x]=2n$
\end{itemize}
Example of a $\chi^2[3]$ distribution:

\begin{figure}[H]
\begin{center}
%\scalebox{.36}
{\includegraphics[width=0.45\textwidth]{figures/chi2_pdf}
\includegraphics[width=0.45\textwidth]{figures/chi2_cdf}}\label{f2}\end{center}
\end{figure}
\end{frame}



\section{The F-distribution}
\begin{frame}{The F-distribution}
If $x_{1}$ and $x_{2}$ are two independent chi-squared variables with degrees of freedom parameters
   $n_{1}$ and $n_{2}$, respectively, then the ratio
   \begin{equation}\label{eq11}
    F [n_{1}, n_{2}] = \frac{x_{1}/n_{1}}{x_{2}/n_{2}}
   \end{equation}
   has the $\textbf{F distribution}$ with $n_{1}$ and $n_{2}$ degrees of freedom.

\begin{figure}[H]
\begin{center}
%\scalebox{.36}
{\includegraphics[width=0.45\textwidth]{figures/F_pdf}
\includegraphics[width=0.45\textwidth]{figures/F_cdf}}\label{f3}
\end{center}
\end{figure}

\end{frame}



\section{The student t-distribution}
\begin{frame}{The student t-distribution}
If $x_1$ is an $N[0, 1]$ variable, often denoted by $z$, and $x_2$ is $\chi^{2}[n_2]$ and is independent of $x_1$, then the ratio
  \begin{equation}\label{eq12}
    t[n_2] = \frac{x_1}{\sqrt{x_2/n_2}}.
  \end{equation}
  has the $\textbf{t distribution}$ with $n_2$ degrees of freedom.
 
Example for the $t$ distributions with $3$ and $10$ degrees of freedom with the standard normal distribution.
\begin{figure}[H]
\begin{center}
%\scalebox{.36}
{\includegraphics[width=0.45\textwidth]{figures/t_pdf}
\includegraphics[width=0.45\textwidth]{figures/t_cdf}}\label{f3}
\end{center}
\end{figure}

Comparing (\ref{eq11}) with $n_{1} = 1$ and (\ref{eq12}), if $t \sim t[n]$, then $t^{2} \sim F[1, n]$.

\end{frame}


\begin{frame}{The $t[30]$ approx. the standard normal}

\includegraphics[width=0.9\textwidth]{figures/t_pdf}
\end{frame}

\begin{frame}{Approximating a $\chi^2$}
For degrees of freedom greater than $30$ the distribution of the chi-squared variable $x$ is approx.
\begin{equation}\label{eq13}
    z = (2x)^{1/2} - (2n - 1)^{1/2},
\end{equation}
which is approximately standard normally distributed. Thus,
\begin{equation*}
    Prob(\chi^{2}[n] \leq a) \approx \Phi[(2a)^{1/2} - (2n - 1)^{1/2}].
\end{equation*}

\begin{figure}[H]
\begin{center}
%\scalebox{.36}
\includegraphics[width=0.6\textwidth]{figures/chi2_cdf_approx
}\label{ch1}
\end{center}
\end{figure}

\end{frame}




\section{The lognormal distribution}
\begin{frame}{The lognormal distribution}
The $\textbf{lognormal distribution}$, denoted $LN[\mu,\sigma^{2}]$, has been particularly
useful in modeling the size distributions.
\begin{equation*}
    f(x) = \frac{1}{\sqrt{2\pi}\sigma x}e^{-\frac{1}{2}[(\ln x-\mu)/\sigma]^{2}},~~~~~~~x>0
\end{equation*}
A lognormal variable $x$ has
\begin{itemize}
	\item  $E[x]= e^{\mu+\sigma^{2}/2},$ and
	\item $Var[x]= e^{2\mu+\sigma^{2}}(e^{\sigma^{2}}-1).$
\end{itemize}

If $y \sim LN[\mu,\sigma^{2}],$ then $\ln y \sim N[\mu,\sigma^{2}].$
\begin{figure}[H]
\begin{center}
%\scalebox{.36}
{\includegraphics[width=0.45\textwidth]{figures/lnnormal_pdf}
\includegraphics[width=0.45\textwidth]{figures/lnnormal_cdf}}\label{f2}
\end{center}
\end{figure}
\end{frame}


\section{The gamma distribution}
\begin{frame}{The gamma distribution}
The general form of the $\textbf{gamma distribution}$ is
\begin{equation}
    f(x) = \frac{\beta^{\alpha}}{\Gamma (\alpha)}e^{-\beta x}x^{\alpha-1},~~~~~~~x\geq0, \beta=1/\theta>0, \alpha=k>0.
\end{equation}
Many familiar distributions are special cases, including the $\textbf{exponential distribution} (\alpha = 1)$ and
$\textbf{chi-squared} (\beta = 1/2 , \alpha = n/2 )$. The $\textbf{Erlang distribution}$ results if $\alpha$ is a positive integer. The mean is
$\alpha/\beta$, and the variance is $\alpha/\beta^{2}$. The $\textbf{inverse gamma distribution}$ is the distribution of $1/x$, where $x$ has the gamma distribution.
\begin{figure}[H]
\begin{center}
%\scalebox{.36}
{\includegraphics[width=0.45\textwidth]{figures/gamma_pdf}
\includegraphics[width=0.45\textwidth]{figures/gamma_cdf}}\label{f2}
\end{center}
\end{figure}
\end{frame}


\section{The beta distribution}
\begin{frame}{The beta distribution}
For a variable constrained between $0$ and $c > 0$, the $\textbf{beta distribution}$ has proved useful. Its density is
\begin{equation*}
    f(x) = \frac{\Gamma(\alpha+\beta)}{\Gamma (\alpha)\Gamma(\beta)}\left(\frac{x}{c}\right)^{\alpha-1}\left(1-\frac{x}{c}\right)^{\beta-1}\frac{1}{c},~~~~~~~0\leq x\leq1.
\end{equation*}
It is symmetric if $\alpha = \beta$, asymmetric otherwise.  The mean is $ca/(\alpha + \beta)$,
and the variance is $c^{2}\alpha\beta/[(\alpha +\beta +1)(\alpha +\beta)^{2}]$.
\begin{figure}[H]
\begin{center}
{\includegraphics[width=0.45\textwidth]{figures/beta_pdf}
\includegraphics[width=0.45\textwidth]{figures/beta_cdf}}\label{f2}
\end{center}
\end{figure}
\end{frame}


\section{The logistic distribution}
\begin{frame}{The logistic distribution}
The $\textbf{logistic distribution}$ is an alternative if the normal cannot model the mass in the tails; the cdf for a logistic random variable with $\mu=0, s=1$ is
\begin{equation*}
    F(x) =\Lambda(x)= \frac{1}{1+e^{-x}}.
\end{equation*}
The density is $f(x) = \Lambda(x)[1 - \Lambda(x)]$. The mean and variance of this random variable are zero
and $\sigma^2=\pi^{2}/3$.
\begin{figure}[H]
\begin{center}
{\includegraphics[width=0.5\textwidth]{figures/normal_logistic_cdf}}\label{f2}
\end{center}
\end{figure}
\end{frame}



\section{The Wishart distribution}
\begin{frame}{The Wishart distribution}

{ The $\textbf{Wishart distribution}$ describes the distribution of a random matrix obtained as
\begin{equation*}
    f(\bm{W}) =\sum_{i=1}^{n}(x_{i}-\mu)(x_{i}-\mu)^{\prime}.
\end{equation*}
where $x_{i}$ is the $i$th of $n K$ element random vectors from the multivariate normal distribution with
mean vector, $\mu$, and covariance matrix, $\Sigma$.  The density of the Wishart random matrix is
\begin{equation*}
    f(\bm{W}) =\frac{\exp\left[-\frac{1}{2}trace(\Sigma^{-1}\bm{W})\right]|\bm{W}|^{-\frac{1}{2}(n-K-1)}}{2^{nK/2}|\Sigma|^{K/2}\pi^{K(K-1)/4}\prod_{j=1}^{K}\Gamma\left(\frac{n+1-j}{2}\right)}.
\end{equation*}
The mean matrix is $n\Sigma$. For the individual pairs of elements in $\bm{W}$,
\begin{equation*}
    Cov[w_{ij}, w_{rs}] = n(\sigma_{ir}\sigma_{js} + \sigma_{is}\sigma_{jr}).
\end{equation*}}
The Wishart distribution is a multivariate extension of $\chi^2$ distribution. If $\bm{W}\sim W(n,\sigma^2)$, then $\bm{W}/\sigma^2\sim\chi^2[n].$
\end{frame}


\section{Common distributions and their properties}

\begin{frame}{Common distributions and their properties}
\begin{table}
%\vspace{-2mm}\centering
{
%\begin{tabular}{l*{5}{D{.}{.}{-1}}}
\begin{footnotesize}
\begin{tabular}{@{\extracolsep{4pt}}l*{4}{l}}
\toprule
 & Normal & Logistic \\
\midrule
Parameters &$\mu\in\mathbb{R}$ , $\sigma\in\mathbb{R}_{>0}$        &  $\mu\in\mathbb{R}$ , $s\in\mathbb{R}_{>0}$   \\
Support    & $x\in\mathbb{R}$                                        &   $x \in \mathbb{R}$    \\
PDF        & $\phi\left(\frac{x-\mu}{\sigma}\right)=\frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{1}{2}\left(\frac{x - \mu}{\sigma}\right)^2}$  &  $\lambda\left(\frac{x-\mu}{s}\right)=\frac{e^{-(x-\mu)/s}} {s\left(1+e^{-(x-\mu)/s}\right)^2}$ \\
CDF        & $\Phi\left(\frac{x-\mu}{\sigma}\right) = \frac{1}{2}\left[1 + \operatorname{erf}\left( \frac{x-\mu}{\sigma\sqrt{2}}\right)\right] $  &  $\Lambda\left(\frac{x-\mu}{s}\right)=\frac{1}{1+e^{-(x-\mu)/s}}$ \\
Mean       & $\mu$  &  $\mu$   \\
Median     & $\mu$  & $\mu$     \\
Mode       & $\mu$  &  $\mu$    \\
Variance   & $\sigma^2$  & $\frac{s^2 \pi^2}{3}$      \\
Skewness   &  $0$ & $0$ \\
Ex. Kurtosis   &  $0$ & $6/5$    \\
MGF        &  $\exp(\mu t + \sigma^2t^2/2)$ &  $e^{\mu t}B(1-st, 1+st)$    \\
           &        &for $t \in (-1/s,1/s)$   \\
\bottomrule
\end{tabular}
\end{footnotesize}
\begin{itemize}
\begin{tiny}
\item PDF denotes probability density function, CDF cumulative distribution function, MGF moment-generating function.
\item $\mu$ mean (location), $\sigma, s$ (scale).
\item $B(z_1,z_2)$ is beta function $\int_0^1 t^{z_1-1}(1-t)^{z_2-1}\,dt$ for complex number inputs $z_1, z_2$ with $\Re(z_1),\Re(z_2) > 0$.
\item Excess Kurtosis is defined as Kurtosis minus 3.
%\item $k, n_1, n_2$ known as ``degrees of freedom''.
%\item regularized incomplete beta function $I_x(a,b) = \frac{B(x;\,a,b)}{B(a,b)}.$
\end{tiny}
\end{itemize}
}

\end{table}
\end{frame}



\begin{frame}{Common distributions and their properties}
\begin{table}
%\vspace{-5mm}\centering
{
%\begin{tabular}{l*{5}{D{.}{.}{-1}}}
\begin{scriptsize}
\begin{tabular}{@{\extracolsep{0pt}}l*{3}{l}}
\toprule
 & $t$ & Log-normal   \\
\midrule
Parameters & $n\in\mathbb{R}_{>0} $  & $\mu \in\mathbb{R}$ , $\sigma\in\mathbb{R}_{>0}$    \\
Support    & $x \in\mathbb{R}$ & $x \in\mathbb{R}_{>0}$   \\
PDF        & $\frac{\Gamma \left(\frac{\ n+1\ }{ 2 } \right)} {\sqrt{\pi n\ }\ \Gamma \left(\frac{ n }{\ 2\ } \right)} \left(1 + \frac{x^2}{ n } \right)^{-\frac{\ n+1\ }{ 2 }}$ & $\frac{ 1 }{\ x\sigma\sqrt{2\pi\ }\ }\ \exp\left( - \frac{ \left( \ln x  - \mu\ \right)^2}{ 2 \sigma^2 } \right)$   \\
CDF        & $\frac{\ 1\ }{ 2 } + x\ \Gamma \left( \frac{\ n+1\ }{ 2 } \right) \times $
     & $\ \frac{\ 1\ }{2}\left[1 + \operatorname{erf}\left( \frac{\ \ln x - \mu\ }{\sigma\sqrt{2\ }} \right)\right] $   \\
           & $ \frac{{ {}_{2}F_1 }\!\left(\frac{\ 1\ }{ 2 },\ \frac{\ n+1\ }{ 2 };\ \frac{ 3 }{\ 2\ };\ 
           -\frac{~ x^2\ }{ n }\right)}  {\sqrt{\pi n}\ \Gamma \left(\frac{n}{ 2 }\right)}$
     & $= \Phi\left(\frac{\ln(x) -\mu}{\sigma} \right)$\\
Mean       & $\ 0\ $ for $\ n > 1\ $ & $\ \exp\left(\mu + \frac{\sigma^2}{2}\right)\ $ \\
Median     & $\ 0\ $ & $\ \exp(\mu)\ $  \\
Mode       & $\ 0\ $ & $\ \exp\left(\mu - \sigma^2\right)\ $   \\
Variance   & $\frac{ n }{\ n-2\ }\ $ for $\ n > 2,$ & $\left[\exp(\sigma^2) - 1\right]\exp\left( 2\mu + \sigma^2\right )$   \\
   & $\infty$ for $1 < n \le 2$ &   \\
Skewness   & $0$ for $n > 3$ & $\left[\exp\left( \sigma^2 \right) + 2\right] \sqrt{\exp(\sigma^2) - 1}$   \\
Ex. Kurtosis   & $\frac{ 6 }{n-4}$ for $n > 4, \infty$ for $2 < n \le 4$ & $1\exp\left(4\sigma^2 \right) + 2\exp\left(3\sigma^2 \right) + 3\exp\left(2\sigma^2 \right) - 6$   \\
MGF        & does not exist & not determined by its moments  \\
\bottomrule
\end{tabular}
\end{scriptsize}
\begin{itemize}
\begin{tiny}
\item $n$ denote degrees of freedom.
\item $\ {}_{2}F_1\!(\cdot,\cdot;\cdot;\cdot)\ $ is a particular instance of the hypergeometric function.
\end{tiny}
\end{itemize}
}

\end{table}
\end{frame}


\begin{frame}{Common distributions and their properties}
\begin{table}
%\vspace{-5mm}\centering
{
%\begin{tabular}{l*{5}{D{.}{.}{-1}}}
\begin{footnotesize}
\begin{tabular}{@{\extracolsep{4pt}}l*{4}{l}}
\toprule
 & $\Gamma$ & $\Gamma$  \\
\midrule
Parameters & $k > 0\in\mathbb{R}$ (shape), & $\alpha > 0\in\mathbb{R}$ (shape), &  \\
           & $\theta > 0\in\mathbb{R}$ scale & $\beta > 0\in\mathbb{R}$ (rate) &  \\
Support    & $x \in\mathbb{R}(0, \infty)$ & $x \in\mathbb{R}(0, \infty)$ &  \\
           &  &  &  \\
PDF        & $f(x)=\frac{1}{\Gamma(k) \theta^k} x^{k - 1} e^{-x/\theta}$ & $f(x)=\frac{\beta^\alpha}{\Gamma(\alpha)} x^{\alpha - 1} e^{-\beta x }$ &  \\
CDF        & $F(x)=\frac{1}{\Gamma(k)} \gamma\left(k, \frac{x}{\theta}\right)$ & $F(x)=\frac{1}{\Gamma(\alpha)} \gamma(\alpha, \beta x)$ &  \\
Mean       & $k \theta $ & $\frac{\alpha}{\beta}$ &  \\
Median     & No simple closed form &  No simple closed form &  \\
Mode       & $(k - 1)\theta \text{ for } k \geq 1$, $0 \text{ for } k < 1$ & $\frac{\alpha - 1}{\beta} \text{ for } \alpha \geq 1\text{, }0 \text{ for } \alpha < 1$ &  \\
Variance   & $k \theta^2$ & $\frac{\alpha}{\beta^2}$ &  \\
Skewness   & $\frac{2}{\sqrt{k}}$ & $\frac{2}{\sqrt{\alpha}}$ &  \\
Ex. Kurtosis   & $\frac{6}{k}$ & $\frac{6}{\alpha}$ &  \\
MGF        & $(1 - \theta t)^{-k} \text{ for } t < \frac{1}{\theta}$ & $\left(1 - \frac{t}{\beta}\right)^{-\alpha} \text{ for } t < \beta$ &  \\
\bottomrule
\end{tabular}
\end{footnotesize}
\begin{itemize}
\begin{tiny}
\item $\Gamma(z) = \int_0^\infty t^{z-1} e^{-t}\text{ d}t, \qquad \Re(z) > 0$, for complex numbers with a positive real part.
\item lower incomplete gamma function is $\gamma(s,x) = \int_0^x t^{s-1}\,e^{-t}\, dt$, for complex numbers with a positive real part.
\end{tiny}
\end{itemize}
}

\end{table}
\end{frame}

\begin{frame}{Common distributions and their properties}
\begin{table}
%\vspace{-5mm}
\centering
{
%\begin{tabular}{l*{5}{D{.}{.}{-1}}}
\begin{footnotesize}
\begin{tabular}{@{\extracolsep{4pt}}l*{4}{l}}
\toprule
 & $\chi^2$ & $F$ \\
\midrule
Parameters & $n\in\mathbb{N}_{>0}$  & $n_1$, $n_2\in\mathbb{N}_{>0}$    \\
Support    & $x\in\mathbb{R}_{>0}\;$ if $n = 1,$   & $x\in\mathbb{R}_{>0}\;$ if $n_1 = 1$,    \\
           &  else $x \in\mathbb{R}_{\geq0}$    & else $x \in\mathbb{R}_{\geq0}$   \\
PDF        & $\frac{1}{2^{n/2}\Gamma(n/2)}\; x^{n/2-1} e^{-x/2}\; $  & $n_1^{\frac{n_1}{2}} n_2^{\frac{n_2}{2}}  \frac{\Gamma (\frac{n_1+n_2}{2})}{\Gamma (\frac{n_1}{2}) \Gamma (\frac{n_2}{2})}  \frac{x^{\frac{n_1}{2}-1}}{(n_1x+n_2)^\frac{n_1+n_2}{2}}$    \\
CDF        &  $\frac{1}{\Gamma(n/2 )} \; \gamma\left(\frac{n}{2},\,\frac{x}{2}\right)\;$  &  $I\left(\frac{n_1 x}{n_1 x + n_2},\,\tfrac{n_1}{2}, \tfrac{n_2}{2} \right)$   \\
Mean       & $n$  &  $\frac{n_2}{n_2-2}\!$ for $n_2 > 2$    \\
Median     &   No simple closed form & No simple closed form     \\
Mode       &   $\max(n-2,0)\;$ & $\frac{n_1-2}{n_1}\;\frac{n_2}{n_2+2}$ for $n_1 > 2$    \\
Variance   &   $2n\;$ & $\frac{2\,n_2^2\,(n_1+n_2-2)}{n_1 (n_2-2)^2 (n_2-4)}\!$ for $n_2 > 4$     \\
Skewness   &  $\sqrt{8/n}\,$  & $\frac{(2 n_1 + n_2 - 2) \sqrt{8 (n_2-4)}}{(n_2-6) \sqrt{n_1 (n_1 + n_2 -2)}}\!$for $n_2 > 6$    \\
Ex. Kurtosis   &  $\frac{12}{n}$ & $12\frac{n_1(5n_2-22)(n_1+n_2-2)+(n_2-4)(n_2-2)^2}{n_1(n_2-6)(n_2-8)(n_1+n_2-2)}$ for $n_2>8$ \\
MGF        &    $(1-2t)^{-n/2} \text{ for } t < \frac{1}{2}\;$ & does not exist    \\
\bottomrule
\end{tabular}
\end{footnotesize}
\begin{itemize}
\begin{tiny}
\item $n, n_1, n_2$ known as degrees of freedom.
\item Regularized incomplete beta function $I(x,a,b) = \frac{B(x,\,a,b)}{B(a,b)}$ with $B(x,\,a,b) = \int_0^x t^{a-1}\,(1-t)^{b-1}\,dt.$
\end{tiny}
\end{itemize}
}

\end{table}
\end{frame}



\begin{frame}{Common distributions and their properties}
\begin{table}
%\vspace{-5mm}\centering
{
%\begin{tabular}{l*{5}{D{.}{.}{-1}}}
\begin{scriptsize}
\begin{tabular}{@{\extracolsep{4pt}}l*{4}{l}}
\toprule
 & $B$ &   \\
\midrule
Parameters & $\alpha, \beta\in\mathbb{R}_{>0}$  & \\
Support    & $x\in[0, 1]\!$ or $x \in (0, 1)\!$ &  \\
PDF        & $\frac{x^{\alpha-1}(1-x)^{\beta-1}} {B(\alpha,\beta)}\!$ &    \\
CDF        & $I(x,\,\alpha,\beta)\!$ &  &  \\
Mean       & $\frac{\alpha}{\alpha+\beta}\!$ &  \\
Median     & $\begin{matrix}I_{\frac{1}{2}}^{[-1]}(\alpha,\beta)\approx \frac{ \alpha - \tfrac{1}{3} }{ \alpha + \beta - \tfrac{2}{3} }\text{ for }\alpha, \beta >1\end{matrix}$  &  \\
Mode       & $^*$ & \\
Variance   & $\frac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}\!$ &    \\
Skewness   & $\frac{2\,(\beta-\alpha)\sqrt{\alpha+\beta+1}}{(\alpha+\beta+2)\sqrt{\alpha\beta}}$ &    \\
Ex. Kurtosis   & $\frac{6[(\alpha - \beta)^2 (\alpha +\beta + 1) - \alpha \beta (\alpha + \beta + 2)]}{\alpha \beta (\alpha + \beta + 2) (\alpha + \beta + 3)}$  &  \\
MGF        & $1  +\sum_{k=1}^\infty \left( \prod_{r=0}^{k-1} \frac{\alpha+r}{\alpha+\beta+r} \right) \frac{t^k}{k!}$ & &  \\
\bottomrule
\end{tabular}
\end{scriptsize}
\begin{itemize}
\begin{tiny}
\item $B(\alpha,\beta) = \frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha + \beta)}$ and $\Gamma$ is the Gamma function.
\item $\Gamma(z) = \int_0^\infty t^{z-1} e^{-t}\text{ d}t, \qquad \Re(z) > 0$, for complex numbers with a positive real part.
\item Regularized incomplete beta function $I(x,\,a,b) = \frac{B(x,\,a,b)}{B(a,b)}$ with $B(x,\,a,b) = \int_0^x t^{a-1}\,(1-t)^{b-1}\,dt.$
\item  $^*\frac{\alpha-1}{\alpha+\beta-2}\, \text{for}\,\alpha, \beta > 1; \text{any value in} (0,1)\, \text{for }\,\alpha, \beta = 1; \{0, 1\}\, \text{(bimodal)}\, \text{for }\,\alpha, \beta < 1; 0\, \text{for }\,\alpha \leq 1, \beta > 1; 1\, \text{for }\,\alpha > 1, \beta \leq 1.$
\end{tiny}
\end{itemize}
}

\end{table}
\end{frame}




\begin{frame}[t,allowframebreaks
]\nocite{*}
\frametitle{References}
\small
\bibliography{bib}
\end{frame}


\end{document}
